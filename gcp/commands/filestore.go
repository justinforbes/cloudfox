package commands

import (
	"context"
	"fmt"
	"strings"
	"sync"

	filestoreservice "github.com/BishopFox/cloudfox/gcp/services/filestoreService"
	"github.com/BishopFox/cloudfox/globals"
	"github.com/BishopFox/cloudfox/internal"
	gcpinternal "github.com/BishopFox/cloudfox/internal/gcp"
	"github.com/spf13/cobra"
)

var GCPFilestoreCommand = &cobra.Command{
	Use:     globals.GCP_FILESTORE_MODULE_NAME,
	Aliases: []string{"nfs", "files"},
	Short:   "Enumerate Filestore NFS instances",
	Long:    `Enumerate Filestore instances and their file shares.`,
	Run:     runGCPFilestoreCommand,
}

type FilestoreModule struct {
	gcpinternal.BaseGCPModule
	ProjectInstances map[string][]filestoreservice.FilestoreInstanceInfo // projectID -> instances
	LootMap          map[string]map[string]*internal.LootFile            // projectID -> loot files
	mu               sync.Mutex
}

type FilestoreOutput struct {
	Table []internal.TableFile
	Loot  []internal.LootFile
}

func (o FilestoreOutput) TableFiles() []internal.TableFile { return o.Table }
func (o FilestoreOutput) LootFiles() []internal.LootFile   { return o.Loot }

func runGCPFilestoreCommand(cmd *cobra.Command, args []string) {
	cmdCtx, err := gcpinternal.InitializeCommandContext(cmd, globals.GCP_FILESTORE_MODULE_NAME)
	if err != nil {
		return
	}

	module := &FilestoreModule{
		BaseGCPModule:    gcpinternal.NewBaseGCPModule(cmdCtx),
		ProjectInstances: make(map[string][]filestoreservice.FilestoreInstanceInfo),
		LootMap:          make(map[string]map[string]*internal.LootFile),
	}
	module.Execute(cmdCtx.Ctx, cmdCtx.Logger)
}

func (m *FilestoreModule) getAllInstances() []filestoreservice.FilestoreInstanceInfo {
	var all []filestoreservice.FilestoreInstanceInfo
	for _, instances := range m.ProjectInstances {
		all = append(all, instances...)
	}
	return all
}

func (m *FilestoreModule) Execute(ctx context.Context, logger internal.Logger) {
	m.RunProjectEnumeration(ctx, logger, m.ProjectIDs, globals.GCP_FILESTORE_MODULE_NAME, m.processProject)

	allInstances := m.getAllInstances()
	if len(allInstances) == 0 {
		logger.InfoM("No Filestore instances found", globals.GCP_FILESTORE_MODULE_NAME)
		return
	}

	logger.SuccessM(fmt.Sprintf("Found %d Filestore instance(s)", len(allInstances)), globals.GCP_FILESTORE_MODULE_NAME)
	m.writeOutput(ctx, logger)
}

func (m *FilestoreModule) processProject(ctx context.Context, projectID string, logger internal.Logger) {
	m.mu.Lock()
	// Initialize loot for this project
	if m.LootMap[projectID] == nil {
		m.LootMap[projectID] = make(map[string]*internal.LootFile)
		m.LootMap[projectID]["filestore-commands"] = &internal.LootFile{
			Name:     "filestore-commands",
			Contents: "# Filestore Commands\n# Generated by CloudFox\n# WARNING: Only use with proper authorization\n\n",
		}
	}
	m.mu.Unlock()

	svc := filestoreservice.New()
	instances, err := svc.ListInstances(projectID)
	if err != nil {
		m.CommandCounter.Error++
		gcpinternal.HandleGCPError(err, logger, globals.GCP_FILESTORE_MODULE_NAME,
			fmt.Sprintf("Could not enumerate Filestore instances in project %s", projectID))
		return
	}

	m.mu.Lock()
	m.ProjectInstances[projectID] = instances
	for _, instance := range instances {
		m.addToLoot(projectID, instance)
	}
	m.mu.Unlock()
}

func (m *FilestoreModule) addToLoot(projectID string, instance filestoreservice.FilestoreInstanceInfo) {
	lootFile := m.LootMap[projectID]["filestore-commands"]
	if lootFile == nil {
		return
	}
	// Determine protocol display name
	protocol := instance.Protocol
	if protocol == "" {
		protocol = "NFS_V3" // Default
	}

	lootFile.Contents += fmt.Sprintf(
		"# =============================================================================\n"+
			"# Instance: %s\n"+
			"# =============================================================================\n"+
			"# Location: %s\n"+
			"# Project: %s\n"+
			"# Protocol: %s\n"+
			"# Tier: %s\n"+
			"# Network: %s\n"+
			"# IP(s): %s\n\n",
		instance.Name,
		instance.Location,
		instance.ProjectID,
		protocol,
		instance.Tier,
		instance.Network,
		strings.Join(instance.IPAddresses, ", "),
	)

	// gcloud describe command
	lootFile.Contents += fmt.Sprintf(
		"# Describe instance:\n"+
			"gcloud filestore instances describe %s --location=%s --project=%s\n\n",
		instance.Name, instance.Location, instance.ProjectID,
	)

	// Mount commands for each share
	if len(instance.Shares) > 0 && len(instance.IPAddresses) > 0 {
		for _, share := range instance.Shares {
			lootFile.Contents += fmt.Sprintf(
				"# -----------------------------------------------------------------------------\n"+
					"# Share: %s (%d GB)\n"+
					"# -----------------------------------------------------------------------------\n",
				share.Name, share.CapacityGB,
			)

			// Show NFS export options if present
			if len(share.NfsExportOptions) > 0 {
				lootFile.Contents += "# NFS Export Options:\n"
				for _, opt := range share.NfsExportOptions {
					ipRanges := strings.Join(opt.IPRanges, ", ")
					if ipRanges == "" {
						ipRanges = "all"
					}
					lootFile.Contents += fmt.Sprintf(
						"#   IP Ranges: %s\n"+
							"#   Access: %s\n"+
							"#   Squash: %s\n",
						ipRanges,
						opt.AccessMode,
						opt.SquashMode,
					)
					if opt.SquashMode == "NO_ROOT_SQUASH" {
						lootFile.Contents += "#   [!] NO_ROOT_SQUASH - root access preserved!\n"
					}
				}
				lootFile.Contents += "\n"
			}

			// Generate mount commands based on protocol
			for _, ip := range instance.IPAddresses {
				lootFile.Contents += "# Mount commands (run as root):\n"

				switch protocol {
				case "NFS_V4_1":
					// NFSv4.1 mount command
					lootFile.Contents += fmt.Sprintf(
						"# NFSv4.1 mount:\n"+
							"sudo mkdir -p /mnt/%s\n"+
							"sudo mount -t nfs -o vers=4.1 %s:/%s /mnt/%s\n"+
							"# With Kerberos (if configured):\n"+
							"# sudo mount -t nfs -o vers=4.1,sec=krb5p %s:/%s /mnt/%s\n\n",
						share.Name,
						ip, share.Name, share.Name,
						ip, share.Name, share.Name,
					)
				default: // NFS_V3 or empty
					// NFSv3 mount command
					lootFile.Contents += fmt.Sprintf(
						"# NFSv3 mount:\n"+
							"sudo mkdir -p /mnt/%s\n"+
							"sudo mount -t nfs -o vers=3 %s:/%s /mnt/%s\n\n",
						share.Name,
						ip, share.Name, share.Name,
					)
				}

				// List contents after mounting
				lootFile.Contents += fmt.Sprintf(
					"# After mounting, list contents:\n"+
						"ls -la /mnt/%s\n"+
						"# Check disk usage:\n"+
						"df -h /mnt/%s\n\n",
					share.Name, share.Name,
				)

				// Unmount command
				lootFile.Contents += fmt.Sprintf(
					"# Unmount when done:\n"+
						"sudo umount /mnt/%s\n\n",
					share.Name,
				)
			}
		}
	}
}

func (m *FilestoreModule) writeOutput(ctx context.Context, logger internal.Logger) {
	if m.Hierarchy != nil && !m.FlatOutput {
		m.writeHierarchicalOutput(ctx, logger)
	} else {
		m.writeFlatOutput(ctx, logger)
	}
}

func (m *FilestoreModule) getHeader() []string {
	return []string{
		"Project Name",
		"Project ID",
		"Name",
		"Location",
		"Tier",
		"Protocol",
		"Network",
		"IP",
		"Shares",
		"Access",
		"Security",
		"State",
	}
}

func (m *FilestoreModule) instancesToTableBody(instances []filestoreservice.FilestoreInstanceInfo) [][]string {
	var body [][]string
	for _, instance := range instances {
		var shareNames []string
		var accessModes []string
		hasNoRootSquash := false

		for _, share := range instance.Shares {
			shareNames = append(shareNames, fmt.Sprintf("%s (%dGB)", share.Name, share.CapacityGB))
			for _, opt := range share.NfsExportOptions {
				if opt.AccessMode != "" {
					accessModes = append(accessModes, opt.AccessMode)
				}
				if opt.SquashMode == "NO_ROOT_SQUASH" {
					hasNoRootSquash = true
				}
			}
		}

		ip := strings.Join(instance.IPAddresses, ", ")
		if ip == "" {
			ip = "-"
		}

		shares := strings.Join(shareNames, ", ")
		if shares == "" {
			shares = "-"
		}

		network := instance.Network
		if network == "" {
			network = "-"
		}

		protocol := instance.Protocol
		if protocol == "" {
			protocol = "NFS_V3"
		}

		// Deduplicate and format access modes
		access := "-"
		if len(accessModes) > 0 {
			uniqueAccess := make(map[string]bool)
			for _, a := range accessModes {
				uniqueAccess[a] = true
			}
			var accessList []string
			for a := range uniqueAccess {
				accessList = append(accessList, a)
			}
			access = strings.Join(accessList, ", ")
		}

		// Security findings
		security := "OK"
		if hasNoRootSquash {
			security = "NO_ROOT_SQUASH"
		}

		body = append(body, []string{
			m.GetProjectName(instance.ProjectID),
			instance.ProjectID,
			instance.Name,
			instance.Location,
			instance.Tier,
			protocol,
			network,
			ip,
			shares,
			access,
			security,
			instance.State,
		})
	}
	return body
}

func (m *FilestoreModule) buildTablesForProject(projectID string) []internal.TableFile {
	var tableFiles []internal.TableFile

	if instances, ok := m.ProjectInstances[projectID]; ok && len(instances) > 0 {
		tableFiles = append(tableFiles, internal.TableFile{
			Name:   "filestore",
			Header: m.getHeader(),
			Body:   m.instancesToTableBody(instances),
		})
	}

	return tableFiles
}

func (m *FilestoreModule) writeHierarchicalOutput(ctx context.Context, logger internal.Logger) {
	outputData := internal.HierarchicalOutputData{
		OrgLevelData:     make(map[string]internal.CloudfoxOutput),
		ProjectLevelData: make(map[string]internal.CloudfoxOutput),
	}

	for projectID := range m.ProjectInstances {
		tableFiles := m.buildTablesForProject(projectID)

		var lootFiles []internal.LootFile
		if projectLoot, ok := m.LootMap[projectID]; ok {
			for _, loot := range projectLoot {
				if loot != nil && loot.Contents != "" && !strings.HasSuffix(loot.Contents, "# WARNING: Only use with proper authorization\n\n") {
					lootFiles = append(lootFiles, *loot)
				}
			}
		}

		outputData.ProjectLevelData[projectID] = FilestoreOutput{Table: tableFiles, Loot: lootFiles}
	}

	pathBuilder := m.BuildPathBuilder()

	err := internal.HandleHierarchicalOutputSmart("gcp", m.Format, m.Verbosity, m.WrapTable, pathBuilder, outputData)
	if err != nil {
		logger.ErrorM(fmt.Sprintf("Error writing hierarchical output: %v", err), globals.GCP_FILESTORE_MODULE_NAME)
	}
}

func (m *FilestoreModule) writeFlatOutput(ctx context.Context, logger internal.Logger) {
	allInstances := m.getAllInstances()

	var tables []internal.TableFile

	if len(allInstances) > 0 {
		tables = append(tables, internal.TableFile{
			Name:   "filestore",
			Header: m.getHeader(),
			Body:   m.instancesToTableBody(allInstances),
		})
	}

	var lootFiles []internal.LootFile
	for _, projectLoot := range m.LootMap {
		for _, loot := range projectLoot {
			if loot != nil && loot.Contents != "" && !strings.HasSuffix(loot.Contents, "# WARNING: Only use with proper authorization\n\n") {
				lootFiles = append(lootFiles, *loot)
			}
		}
	}

	output := FilestoreOutput{
		Table: tables,
		Loot:  lootFiles,
	}

	scopeNames := make([]string, len(m.ProjectIDs))
	for i, id := range m.ProjectIDs {
		scopeNames[i] = m.GetProjectName(id)
	}

	internal.HandleOutputSmart("gcp", m.Format, m.OutputDirectory, m.Verbosity, m.WrapTable,
		"project", m.ProjectIDs, scopeNames, m.Account, output)
}
